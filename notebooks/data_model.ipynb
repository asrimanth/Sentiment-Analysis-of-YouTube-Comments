{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sl_no</th>\n",
       "      <th>video_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>likes</th>\n",
       "      <th>last_update_time</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>stemmed_clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>IBe2o-cZncU</td>\n",
       "      <td>UCETH_ePd6_jXtrT9hvJ8EAg</td>\n",
       "      <td>Singularity: The day you wanna turn off your p...</td>\n",
       "      <td>58</td>\n",
       "      <td>2019-12-14T03:30:13.000Z</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>singular the day you wan na turn off your pc b...</td>\n",
       "      <td>['singular', 'day', 'wan', 'turn', 'pc', 'refus']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>IBe2o-cZncU</td>\n",
       "      <td>UCVYV59yMBaZfUfbKRvIrsGQ</td>\n",
       "      <td>Jack Ma AI: Alibaba Intelligence</td>\n",
       "      <td>930</td>\n",
       "      <td>2019-12-09T13:00:25.000Z</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>jack Ma AI alibaba intellig</td>\n",
       "      <td>['jack', 'Ma', 'AI', 'alibaba', 'intellig']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>IBe2o-cZncU</td>\n",
       "      <td>UCw40cwbkNDrFpdd4YUig3iw</td>\n",
       "      <td>Alan Turing deserve recognition for his work o...</td>\n",
       "      <td>136</td>\n",
       "      <td>2019-12-09T13:34:53.000Z</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>positive</td>\n",
       "      <td>alan ture deserv recognit for hi work on learn...</td>\n",
       "      <td>['alan', 'ture', 'deserv', 'recognit', 'hi', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>IBe2o-cZncU</td>\n",
       "      <td>UCmrcSjCCikF4I68gMdRV64A</td>\n",
       "      <td>Your production house gives us the fascinating...</td>\n",
       "      <td>653</td>\n",
       "      <td>2019-12-09T12:54:02.000Z</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>positive</td>\n",
       "      <td>your product hous give us the fascin tech vide...</td>\n",
       "      <td>['product', 'hous', 'give', 'us', 'fascin', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>IBe2o-cZncU</td>\n",
       "      <td>UChC_nPFZN2_OwogxYTC_TMQ</td>\n",
       "      <td>Sarah Connor is watching this and making a list</td>\n",
       "      <td>126</td>\n",
       "      <td>2019-12-09T15:16:38.000Z</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sarah connor is watch thi and make a list</td>\n",
       "      <td>['sarah', 'connor', 'watch', 'make', 'list']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sl_no     video_id                   user_id  \\\n",
       "0           0      1  IBe2o-cZncU  UCETH_ePd6_jXtrT9hvJ8EAg   \n",
       "1           1      2  IBe2o-cZncU  UCVYV59yMBaZfUfbKRvIrsGQ   \n",
       "2           2      3  IBe2o-cZncU  UCw40cwbkNDrFpdd4YUig3iw   \n",
       "3           3      4  IBe2o-cZncU  UCmrcSjCCikF4I68gMdRV64A   \n",
       "4           4      5  IBe2o-cZncU  UChC_nPFZN2_OwogxYTC_TMQ   \n",
       "\n",
       "                                             comment  likes  \\\n",
       "0  Singularity: The day you wanna turn off your p...     58   \n",
       "1                   Jack Ma AI: Alibaba Intelligence    930   \n",
       "2  Alan Turing deserve recognition for his work o...    136   \n",
       "3  Your production house gives us the fascinating...    653   \n",
       "4    Sarah Connor is watching this and making a list    126   \n",
       "\n",
       "           last_update_time  sentiment sentiment_label  \\\n",
       "0  2019-12-14T03:30:13.000Z     0.0000         neutral   \n",
       "1  2019-12-09T13:00:25.000Z     0.0000         neutral   \n",
       "2  2019-12-09T13:34:53.000Z     0.4000        positive   \n",
       "3  2019-12-09T12:54:02.000Z     0.5125        positive   \n",
       "4  2019-12-09T15:16:38.000Z     0.0000         neutral   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0  singular the day you wan na turn off your pc b...   \n",
       "1                       jack Ma AI alibaba intellig    \n",
       "2  alan ture deserv recognit for hi work on learn...   \n",
       "3  your product hous give us the fascin tech vide...   \n",
       "4         sarah connor is watch thi and make a list    \n",
       "\n",
       "                                  stemmed_clean_text  \n",
       "0  ['singular', 'day', 'wan', 'turn', 'pc', 'refus']  \n",
       "1        ['jack', 'Ma', 'AI', 'alibaba', 'intellig']  \n",
       "2  ['alan', 'ture', 'deserv', 'recognit', 'hi', '...  \n",
       "3  ['product', 'hous', 'give', 'us', 'fascin', 't...  \n",
       "4       ['sarah', 'connor', 'watch', 'make', 'list']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/srimanth/Programs/project_4-2/ytube_clean.csv\")\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction\n",
    "\n",
    "corpus = list(df['stemmed_text'])\n",
    "corpus = [item.lower() for item in corpus]\n",
    "\n",
    "vectorizer = feature_extraction.text.CountVectorizer(analyzer='word', stop_words='english')\n",
    "bow = vectorizer.fit_transform(corpus)\n",
    "feature_list = vectorizer.get_feature_names()\n",
    "\n",
    "X_bow = pd.DataFrame(bow.toarray(),columns=vectorizer.get_feature_names())\n",
    "y = df[\"sentiment_label\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1193, 3499)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "True: 227, False: 72\n"
     ]
    }
   ],
   "source": [
    "bool_array = (model.predict(X_test) == np.array(y_test))\n",
    "print(len(bool_array))\n",
    "count = np.count_nonzero(bool_array)\n",
    "print(\"True: {}, False: {}\".format(count, len(bool_array)-count)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1492, 843)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.7)  \n",
    "\n",
    "tf_idf = tfidf_vectorizer.fit_transform(corpus)\n",
    "feature_list = tfidf_vectorizer.get_feature_names()\n",
    "X_tf_idf = pd.DataFrame(tf_idf.toarray(),columns=feature_list)  \n",
    "\n",
    "X_tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(X_bow, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tf, y_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "True: 227, False: 72\n"
     ]
    }
   ],
   "source": [
    "bool_array = (model.predict(X_test_tf) == np.array(y_test_tf))\n",
    "print(len(bool_array))\n",
    "count = np.count_nonzero(bool_array)\n",
    "print(\"True: {}, False: {}\".format(count, len(bool_array)-count)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def metrics(predictions, y_test):\n",
    "    print(confusion_matrix(y_test,predictions))  \n",
    "    print(classification_report(y_test,predictions))  \n",
    "    print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  6 183  37]\n",
      " [  0  28  44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "     neutral       0.86      0.81      0.84       226\n",
      "    positive       0.54      0.61      0.58        72\n",
      "\n",
      "    accuracy                           0.76       299\n",
      "   macro avg       0.47      0.47      0.47       299\n",
      "weighted avg       0.78      0.76      0.77       299\n",
      "\n",
      "0.7591973244147158\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  6 183  37]\n",
      " [  0  28  44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "     neutral       0.86      0.81      0.84       226\n",
      "    positive       0.54      0.61      0.58        72\n",
      "\n",
      "    accuracy                           0.76       299\n",
      "   macro avg       0.47      0.47      0.47       299\n",
      "weighted avg       0.78      0.76      0.77       299\n",
      "\n",
      "0.7591973244147158\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test_tf, model.predict(X_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
